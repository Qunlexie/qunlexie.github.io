<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <title>Gen AI System Design (Text Generation, RAG) - Notes</title>
    <link rel="stylesheet" href="../assets/style.css?v=1759443295" />
    <style>
      /* Additional styles for notes page - always visible */
      .notes-content {
        display: block !important;
      }
      
      /* aman.ai inspired styles */
      .notes-header {
        text-align: center;
        margin: 2rem 0;
      }
      
      .notes-header h1 {
        font-size: 2.5rem;
        margin-bottom: 0.5rem;
      }
      
      .notes-header .subtitle {
        color: #666;
        font-style: italic;
      }
      
      .category-section {
        background: white;
        padding: 1.5rem;
        margin-bottom: 2rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      }
      
      .category-section h2 {
        font-size: 1.5rem;
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #007bff;
      }
      
      .back-link {
        display: inline-block;
        margin-bottom: 1rem;
        color: #007bff;
        text-decoration: none;
        font-weight: 500;
      }
      
      .back-link:hover {
        text-decoration: underline;
      }
      
      /* Table of Contents Styles */
      .table-of-contents {
        background: #f8f9fa;
        border: 1px solid #e9ecef;
        border-radius: 8px;
        padding: 1.5rem;
        margin-bottom: 2rem;
      }
      
      .table-of-contents h3 {
        margin-top: 0;
        margin-bottom: 1rem;
        color: #495057;
        font-size: 1.2rem;
      }
      
      .toc-list {
        list-style: none;
        padding-left: 0;
        margin: 0;
      }
      
      .toc-list li {
        margin-bottom: 0.5rem;
      }
      
      .toc-list a {
        color: #007bff;
        text-decoration: none;
        font-weight: 500;
        display: block;
        padding: 0.25rem 0;
        border-radius: 4px;
        transition: all 0.2s ease;
      }
      
      .toc-list a:hover {
        background-color: #e7f3ff;
        padding-left: 0.5rem;
        text-decoration: none;
      }
      
      .question {
        margin-top: 2rem;
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 1px solid #e9ecef;
      }
      
      /* Back to Top Button */
      .back-to-top {
        position: fixed;
        bottom: 30px;
        right: 30px;
        background: #007bff;
        color: white;
        border: none;
        border-radius: 50%;
        width: 50px;
        height: 50px;
        font-size: 18px;
        cursor: pointer;
        box-shadow: 0 4px 12px rgba(0,123,255,0.3);
        transition: all 0.3s ease;
        opacity: 0;
        visibility: hidden;
        z-index: 1000;
      }
      
      .back-to-top:hover {
        background: #0056b3;
        transform: translateY(-2px);
        box-shadow: 0 6px 16px rgba(0,123,255,0.4);
      }
      
      .back-to-top.visible {
        opacity: 1;
        visibility: visible;
      }
      
      .back-to-top .icon {
        display: inline-block;
        transform: rotate(-90deg);
      }
      
      /* References section styling */
      .references-section {
        background: #f8f9fa;
        border: 1px solid #e9ecef;
        border-radius: 8px;
        padding: 1.5rem;
        margin-top: 2rem;
      }
      
      .references-section h3 {
        margin-top: 0;
        margin-bottom: 1rem;
        color: #495057;
        font-size: 1.2rem;
      }
      
      .references-list {
        margin: 0;
        padding-left: 1.5rem;
      }
      
      .references-list li {
        margin-bottom: 0.5rem;
        line-height: 1.5;
      }
      
      .references-list a {
        color: #007bff;
        text-decoration: none;
        font-weight: 500;
      }
      
      .references-list a:hover {
        text-decoration: underline;
      }
      
      @media (max-width: 768px) {
        .notes-header h1 {
          font-size: 2rem;
        }
        .table-of-contents {
          padding: 1rem;
        }
        .back-to-top {
          bottom: 20px;
          right: 20px;
          width: 45px;
          height: 45px;
          font-size: 16px;
        }
      }
    </style>
  </head>
  <body>
    <!-- Notes Content -->
    <div class="notes-content" id="notesContent">
      <header>
        <nav>
          <ul>
            <li><a href="../pages/index.html">Home</a></li>
            <li><a href="../pages/projects.html">Projects and Research</a></li>
            <li><a href="../pages/highlights.html">Highlights</a></li>
            <li><a href="../pages/notes.html">Notes Hub</a></li>
          </ul>
        </nav>
      </header>
      
      <main>
        <div class="notes-header">
          <h1>Gen AI System Design (Text Generation, RAG)</h1>
          <p class="subtitle">comprehensive revision notes</p>
        </div>

        <div class="category-section">
          <a href="../pages/notes.html" class="back-link">‚Üê Back to Notes Hub</a>
          <h2>Gen AI System Design (Text Generation, RAG)</h2>
          <div style="line-height: 1.8;">
            <div class="table-of-contents">
              <h3>üìã Table of Contents</h3>
              <ul class="toc-list">
                <li><a href="#q-business-requirement--context-">1. Business requirement & context : language support</a></li>
                <li><a href="#q-data-availability-annotated-da">2. Data availability (annotated data? Self supervision?)</a></li>
                <li><a href="#q-scale-qps-number-of-users-peak">3. Scale: QPS, number of users, peak QPS</a></li>
                <li><a href="#q-latency--300ms">4. Latency: < 300ms</a></li>
                <li><a href="#q-outline-">5. Outline ‚Äî></a></li>
                <li><a href="#q-system-choice--input-and-outpu">6. System choice ‚Äî> Input and output and the type of objective.</a></li>
                <li><a href="#q-data-processing">7. Data processing</a></li>
                <li><a href="#q-model">8. Model</a></li>
                <li><a href="#q-safety-filtering-filter-harmfu">9. Safety filtering (filter harmful content from prompt)</a></li>
                <li><a href="#q-prompt-enhancer">10. Prompt enhancer</a></li>
                <li><a href="#q-response-generator">11. Response generator</a></li>
                <li><a href="#q-rejection-response-generator-t">12. Rejection response generator (tell user they cannot generate response that fails safety filtering)</a></li>
                <li><a href="#q-response-safety-evaluator">13. Response safety evaluator</a></li>
                <li><a href="#q-session-management">14. Session management</a></li>
                <li><a href="#q-continual-learning-and-feedbac">15. Continual learning and Feedback integration</a></li>
                <li><a href="#q-pretraining">16. Pretraining:</a></li>
                <li><a href="#q-supervised-finetuning-cleaned-">17. Supervised fine-tuning: cleaned, conversational documents, high quality</a></li>
                <li><a href="#q-deduplication-removing-nsfw-fi">18. Deduplication, removing NSFW, filtering low quality, data sensitivity (privacy)</a></li>
                <li><a href="#q-preprocessing">19. Preprocessing</a></li>
                <li><a href="#q-pros-and-cons-tokenization--co">20. (pros and cons) Tokenization - converting sentences to smaller components/chunks</a></li>
                <li><a href="#q-token-to-ids-these-ids-are-the">21. Token to ids (these ids are then used to represent the text), the text embedding layer in the NN transforms this into an embedding vector which is then learned by the model</a></li>
                <li><a href="#q-addressing-diversity-and-biase">22. Addressing Diversity and biases in the data (Data Augmentation)</a></li>
                <li><a href="#q-tradeoffs-of-options-for-model">23. Trade-offs of options for model architecture and pros and cons. For text, you can talk about RNNs and how they were initially the go-to and the pros and cons vs Transformer architecture.</a></li>
                <li><a href="#q-transformer-architecture-advan">24. Transformer architecture advantages:</a></li>
                <li><a href="#q-pretraining-largescale-unsuper">25. Pretraining: Large-scale unsupervised learning on diverse text</a></li>
                <li><a href="#q-supervised-finetuning-taskspec">26. Supervised Fine-tuning: Task-specific training with labeled data</a></li>
                <li><a href="#q-reinforcement-learning-from-hu">27. Reinforcement Learning from Human Feedback (RLHF):</a></li>
                <li><a href="#q-safety-filtering-input-validat">28. **Safety Filtering**: Input validation and harmful content detection</a></li>
                <li><a href="#q-prompt-enhancement-context-opt">29. **Prompt Enhancement**: Context optimization and instruction following</a></li>
                <li><a href="#q-response-generation-core-langu">30. **Response Generation**: Core language model inference</a></li>
                <li><a href="#q-safety-evaluation-output-valid">31. **Safety Evaluation**: Output validation and content filtering</a></li>
                <li><a href="#q-session-management-context-per">32. **Session Management**: Context persistence and user state</a></li>
                <li><a href="#q-latency-optimization--300ms-ta">33. Latency optimization (< 300ms target)</a></li>
                <li><a href="#q-throughput-scaling-qps-require">34. Throughput scaling (QPS requirements)</a></li>
                <li><a href="#q-memory-management">35. Memory management</a></li>
                <li><a href="#q-caching-strategies">36. Caching strategies</a></li>
                <li><a href="#q-model-serving-infrastructure">37. Model serving infrastructure</a></li>
                <li><a href="#q-load-balancing">38. Load balancing</a></li>
                <li><a href="#q-autoscaling">39. Auto-scaling</a></li>
                <li><a href="#q-monitoring-and-observability">40. Monitoring and observability</a></li>
                <li><a href="#q-realtime-data-ingestion">41. Real-time data ingestion</a></li>
                <li><a href="#q-batch-processing">42. Batch processing</a></li>
                <li><a href="#q-feature-engineering">43. Feature engineering</a></li>
                <li><a href="#q-model-retraining-pipeline">44. Model retraining pipeline</a></li>
                <li><a href="#q-response-time">45. Response time</a></li>
                <li><a href="#q-throughput-qps">46. Throughput (QPS)</a></li>
                <li><a href="#q-model-accuracy">47. Model accuracy</a></li>
                <li><a href="#q-safety-compliance">48. Safety compliance</a></li>
                <li><a href="#q-user-engagement">49. User engagement</a></li>
                <li><a href="#q-task-completion-rate">50. Task completion rate</a></li>
                <li><a href="#q-user-satisfaction">51. User satisfaction</a></li>
                <li><a href="#q-cost-per-interaction">52. Cost per interaction</a></li>
              </ul>
            </div>

            <p id="q-business-requirement--context-" class="question"><strong>Business requirement & context : language support</strong></p>
            <p id="q-data-availability-annotated-da" class="question"><strong>Data availability (annotated data? Self supervision?)</strong></p>
            <p id="q-scale-qps-number-of-users-peak" class="question"><strong>Scale: QPS, number of users, peak QPS</strong></p>
            <p id="q-latency--300ms" class="question"><strong>Latency: < 300ms</strong></p>
            <p id="q-outline-" class="question"><strong>Outline ‚Äî></strong></p>
            <p id="q-system-choice--input-and-outpu" class="question"><strong>System choice ‚Äî> Input and output and the type of objective.</strong></p>
            <p id="q-data-processing" class="question"><strong>Data processing</strong></p>
            <p id="q-model" class="question"><strong>Model</strong></p>
            <ul style="margin-left: 1.5rem;">
              <li>Pretraining</li>
              <li>Supervised finetuning</li>
              <li>Post training: RLHF</li>
            </ul>
            <p id="q-safety-filtering-filter-harmfu" class="question"><strong>Safety filtering (filter harmful content from prompt)</strong></p>
            <p id="q-prompt-enhancer" class="question"><strong>Prompt enhancer</strong></p>
            <p id="q-response-generator" class="question"><strong>Response generator</strong></p>
            <p id="q-rejection-response-generator-t" class="question"><strong>Rejection response generator (tell user they cannot generate response that fails safety filtering)</strong></p>
            <p id="q-response-safety-evaluator" class="question"><strong>Response safety evaluator</strong></p>
            <p id="q-session-management" class="question"><strong>Session management</strong></p>
            <p id="q-continual-learning-and-feedbac" class="question"><strong>Continual learning and Feedback integration</strong></p>
            <p id="q-pretraining" class="question"><strong>Pretraining:</strong></p>
            <ul style="margin-left: 1.5rem;">
              <li>Common crawl dataset -70% ~ 3TB, Cleaned Common Crawl (C4 by Google), Others: GitHub, Stack Exchange, arXiv, Wikipedia (~1.5-2.5 Trillion tokens)</li>
            </ul>
            <p id="q-supervised-finetuning-cleaned-" class="question"><strong>Supervised fine-tuning: cleaned, conversational documents, high quality</strong></p>
            <p id="q-deduplication-removing-nsfw-fi" class="question"><strong>Deduplication, removing NSFW, filtering low quality, data sensitivity (privacy)</strong></p>
            <p id="q-preprocessing" class="question"><strong>Preprocessing</strong></p>
            <ul style="margin-left: 1.5rem;">
              <li>Normalization, lower casing, stop word removal, lemmatization</li>
            </ul>
            <p id="q-pros-and-cons-tokenization--co" class="question"><strong>(pros and cons) Tokenization - converting sentences to smaller components/chunks</strong></p>
            <ul style="margin-left: 1.5rem;">
              <li>Character: hard to learn meaningful representation</li>
              <li>Word: Large vocabulary</li>
              <li>Subword (Byte pair encoding or Sentence Piece) using BPE algorithm that decomposes rare/unknown words into smaller known/frequent words.</li>
            </ul>
            <p id="q-token-to-ids-these-ids-are-the" class="question"><strong>Token to ids (these ids are then used to represent the text), the text embedding layer in the NN transforms this into an embedding vector which is then learned by the model</strong></p>
            <p id="q-addressing-diversity-and-biase" class="question"><strong>Addressing Diversity and biases in the data (Data Augmentation)</strong></p>
            <p id="q-tradeoffs-of-options-for-model" class="question"><strong>Trade-offs of options for model architecture and pros and cons. For text, you can talk about RNNs and how they were initially the go-to and the pros and cons vs Transformer architecture.</strong></p>
            <p id="q-transformer-architecture-advan" class="question"><strong>Transformer architecture advantages:</strong></p>
            <ul style="margin-left: 1.5rem;">
              <li>Parallel processing (vs sequential in RNNs)</li>
              <li>Better long-range dependencies</li>
              <li>Attention mechanism</li>
              <li>Scalability</li>
            </ul>
            <p id="q-pretraining-largescale-unsuper" class="question"><strong>Pretraining: Large-scale unsupervised learning on diverse text</strong></p>
            <p id="q-supervised-finetuning-taskspec" class="question"><strong>Supervised Fine-tuning: Task-specific training with labeled data</strong></p>
            <p id="q-reinforcement-learning-from-hu" class="question"><strong>Reinforcement Learning from Human Feedback (RLHF):</strong></p>
            <ul style="margin-left: 1.5rem;">
              <li>Reward model training</li>
              <li>Policy optimization</li>
              <li>Human preference alignment</li>
            </ul>
            <p id="q-safety-filtering-input-validat" class="question"><strong>**Safety Filtering**: Input validation and harmful content detection</strong></p>
            <p id="q-prompt-enhancement-context-opt" class="question"><strong>**Prompt Enhancement**: Context optimization and instruction following</strong></p>
            <p id="q-response-generation-core-langu" class="question"><strong>**Response Generation**: Core language model inference</strong></p>
            <p id="q-safety-evaluation-output-valid" class="question"><strong>**Safety Evaluation**: Output validation and content filtering</strong></p>
            <p id="q-session-management-context-per" class="question"><strong>**Session Management**: Context persistence and user state</strong></p>
            <p id="q-latency-optimization--300ms-ta" class="question"><strong>Latency optimization (< 300ms target)</strong></p>
            <p id="q-throughput-scaling-qps-require" class="question"><strong>Throughput scaling (QPS requirements)</strong></p>
            <p id="q-memory-management" class="question"><strong>Memory management</strong></p>
            <p id="q-caching-strategies" class="question"><strong>Caching strategies</strong></p>
            <p id="q-model-serving-infrastructure" class="question"><strong>Model serving infrastructure</strong></p>
            <p id="q-load-balancing" class="question"><strong>Load balancing</strong></p>
            <p id="q-autoscaling" class="question"><strong>Auto-scaling</strong></p>
            <p id="q-monitoring-and-observability" class="question"><strong>Monitoring and observability</strong></p>
            <p id="q-realtime-data-ingestion" class="question"><strong>Real-time data ingestion</strong></p>
            <p id="q-batch-processing" class="question"><strong>Batch processing</strong></p>
            <p id="q-feature-engineering" class="question"><strong>Feature engineering</strong></p>
            <p id="q-model-retraining-pipeline" class="question"><strong>Model retraining pipeline</strong></p>
            <p id="q-response-time" class="question"><strong>Response time</strong></p>
            <p id="q-throughput-qps" class="question"><strong>Throughput (QPS)</strong></p>
            <p id="q-model-accuracy" class="question"><strong>Model accuracy</strong></p>
            <p id="q-safety-compliance" class="question"><strong>Safety compliance</strong></p>
            <p id="q-user-engagement" class="question"><strong>User engagement</strong></p>
            <p id="q-task-completion-rate" class="question"><strong>Task completion rate</strong></p>
            <p id="q-user-satisfaction" class="question"><strong>User satisfaction</strong></p>
            <p id="q-cost-per-interaction" class="question"><strong>Cost per interaction</strong></p>
                <li><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Attention Is All You Need - Vaswani et al.</a></li>
                <li><a href="https://arxiv.org/abs/2203.02155" target="_blank" rel="noopener noreferrer">Training language models to follow instructions with human feedback</a></li>
                <li><a href="https://arxiv.org/abs/2212.08073" target="_blank" rel="noopener noreferrer">Constitutional AI: Harmlessness from AI Feedback</a></li>
                <li><a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener noreferrer">Scaling Laws for Neural Language Models</a></li>
                <li><a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noopener noreferrer">Language Models are Few-Shot Learners</a></li>
          </div>
        </div>

      </main>
      
      <footer>
        <p>&copy; 2025 Gen AI System Design (Text Generation, RAG) Notes</p>
      </footer>
    </div>

    <!-- Back to Top Button -->
    <button class="back-to-top" id="backToTop" onclick="scrollToTop()" title="Back to Table of Contents">
      <span class="icon">‚Üí</span>
    </button>

    <script>
      // Notes are now freely accessible - no authentication required
      function checkAuth() {
        // Always show content - knowledge is free!
        document.getElementById('notesContent').style.display = 'block';
      }

      // Scroll to top functionality
      function scrollToTop() {
        window.scrollTo({
          top: 0,
          behavior: 'smooth'
        });
      }

      // Show/hide back to top button based on scroll position
      function toggleBackToTopButton() {
        const backToTopButton = document.getElementById('backToTop');
        if (window.pageYOffset > 300) {
          backToTopButton.classList.add('visible');
        } else {
          backToTopButton.classList.remove('visible');
        }
      }

      // Initialize page
      document.addEventListener('DOMContentLoaded', function() {
        checkAuth();
        
        // Add scroll event listener for back to top button
        window.addEventListener('scroll', toggleBackToTopButton);
      });
    </script>
  </body>
</html>